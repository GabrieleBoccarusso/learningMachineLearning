{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "biological-lucas",
   "metadata": {},
   "source": [
    "## tuning hyperparameters\n",
    "\n",
    "hyperparameters are the variables that will determine how the model <br>\n",
    "will be trained, in order to output the results that we need <br>\n",
    "we have to *tune* them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "presidential-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the evaluating function\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluate_regression_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    evaluate a regression model performance based on four criteria:\n",
    "    accuracy, r2_score, MAE and MSE. I print the scores and create\n",
    "    a dict with the values in it\n",
    "    \"\"\"\n",
    "    r_squared = r2_score(y_true, y_preds)\n",
    "    mae = mean_absolute_error(y_true, y_preds)\n",
    "    mse = mean_squared_error(y_true, y_preds)\n",
    "    metrics_dict = {'R squared': round(r_squared, 2),\n",
    "                    'mean absolute error': round(mae, 2),\n",
    "                    'mean squared error': round(mse, 2)}\n",
    "\n",
    "    print(f'R squared score: {r_squared * 100:.2f}%')\n",
    "    print(f'mean absolute error: {mae * 100:.2f}')\n",
    "    print(f'mean squared error: {mse * 100:.2f}')\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "french-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BUDAPEST</th>\n",
       "      <th>BARANYA</th>\n",
       "      <th>BACS</th>\n",
       "      <th>BEKES</th>\n",
       "      <th>BORSOD</th>\n",
       "      <th>CSONGRAD</th>\n",
       "      <th>FEJER</th>\n",
       "      <th>GYOR</th>\n",
       "      <th>HAJDU</th>\n",
       "      <th>...</th>\n",
       "      <th>JASZ</th>\n",
       "      <th>KOMAROM</th>\n",
       "      <th>NOGRAD</th>\n",
       "      <th>PEST</th>\n",
       "      <th>SOMOGY</th>\n",
       "      <th>SZABOLCS</th>\n",
       "      <th>TOLNA</th>\n",
       "      <th>VAS</th>\n",
       "      <th>VESZPREM</th>\n",
       "      <th>ZALA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/01/2005</td>\n",
       "      <td>168</td>\n",
       "      <td>79</td>\n",
       "      <td>30</td>\n",
       "      <td>173</td>\n",
       "      <td>169</td>\n",
       "      <td>42</td>\n",
       "      <td>136</td>\n",
       "      <td>120</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/01/2005</td>\n",
       "      <td>157</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>92</td>\n",
       "      <td>200</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>141</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>68</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/01/2005</td>\n",
       "      <td>96</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>157</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>62</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/01/2005</td>\n",
       "      <td>163</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>126</td>\n",
       "      <td>46</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>114</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>107</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/01/2005</td>\n",
       "      <td>122</td>\n",
       "      <td>78</td>\n",
       "      <td>53</td>\n",
       "      <td>87</td>\n",
       "      <td>103</td>\n",
       "      <td>34</td>\n",
       "      <td>95</td>\n",
       "      <td>131</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  BUDAPEST  BARANYA  BACS  BEKES  BORSOD  CSONGRAD  FEJER  GYOR  \\\n",
       "0  03/01/2005       168       79    30    173     169        42    136   120   \n",
       "1  10/01/2005       157       60    30     92     200        53     51    70   \n",
       "2  17/01/2005        96       44    31     86      93        30     93    84   \n",
       "3  24/01/2005       163       49    43    126      46        39     52   114   \n",
       "4  31/01/2005       122       78    53     87     103        34     95   131   \n",
       "\n",
       "   HAJDU  ...  JASZ  KOMAROM  NOGRAD  PEST  SOMOGY  SZABOLCS  TOLNA  VAS  \\\n",
       "0    162  ...   130       57       2   178      66        64     11   29   \n",
       "1     84  ...    80       50      29   141      48        29     58   53   \n",
       "2    191  ...    64       46       4   157      33        33     24   18   \n",
       "3    107  ...    63       54      14   107      66        50     25   21   \n",
       "4    172  ...    61       49      11   124      63        56      7   47   \n",
       "\n",
       "   VESZPREM  ZALA  \n",
       "0        87    68  \n",
       "1        68    26  \n",
       "2        62    44  \n",
       "3        43    31  \n",
       "4        85    60  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the hungarian chickenpox dataset\n",
    "import pandas as pd\n",
    "chickenpox = pd.read_csv('data/hungary_chickenpox.csv')\n",
    "chickenpox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "packed-swimming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BUDAPEST</th>\n",
       "      <th>BARANYA</th>\n",
       "      <th>BACS</th>\n",
       "      <th>BEKES</th>\n",
       "      <th>BORSOD</th>\n",
       "      <th>CSONGRAD</th>\n",
       "      <th>FEJER</th>\n",
       "      <th>GYOR</th>\n",
       "      <th>HAJDU</th>\n",
       "      <th>...</th>\n",
       "      <th>KOMAROM</th>\n",
       "      <th>NOGRAD</th>\n",
       "      <th>PEST</th>\n",
       "      <th>SOMOGY</th>\n",
       "      <th>SZABOLCS</th>\n",
       "      <th>TOLNA</th>\n",
       "      <th>VAS</th>\n",
       "      <th>VESZPREM</th>\n",
       "      <th>ZALA</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/01/2005</td>\n",
       "      <td>168</td>\n",
       "      <td>79</td>\n",
       "      <td>30</td>\n",
       "      <td>173</td>\n",
       "      <td>169</td>\n",
       "      <td>42</td>\n",
       "      <td>136</td>\n",
       "      <td>120</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "      <td>68</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/01/2005</td>\n",
       "      <td>157</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>92</td>\n",
       "      <td>200</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>141</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>68</td>\n",
       "      <td>26</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/01/2005</td>\n",
       "      <td>96</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>157</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>62</td>\n",
       "      <td>44</td>\n",
       "      <td>1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/01/2005</td>\n",
       "      <td>163</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>126</td>\n",
       "      <td>46</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>114</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>107</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/01/2005</td>\n",
       "      <td>122</td>\n",
       "      <td>78</td>\n",
       "      <td>53</td>\n",
       "      <td>87</td>\n",
       "      <td>103</td>\n",
       "      <td>34</td>\n",
       "      <td>95</td>\n",
       "      <td>131</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  BUDAPEST  BARANYA  BACS  BEKES  BORSOD  CSONGRAD  FEJER  GYOR  \\\n",
       "0  03/01/2005       168       79    30    173     169        42    136   120   \n",
       "1  10/01/2005       157       60    30     92     200        53     51    70   \n",
       "2  17/01/2005        96       44    31     86      93        30     93    84   \n",
       "3  24/01/2005       163       49    43    126      46        39     52   114   \n",
       "4  31/01/2005       122       78    53     87     103        34     95   131   \n",
       "\n",
       "   HAJDU  ...  KOMAROM  NOGRAD  PEST  SOMOGY  SZABOLCS  TOLNA  VAS  VESZPREM  \\\n",
       "0    162  ...       57       2   178      66        64     11   29        87   \n",
       "1     84  ...       50      29   141      48        29     58   53        68   \n",
       "2    191  ...       46       4   157      33        33     24   18        62   \n",
       "3    107  ...       54      14   107      66        50     25   21        43   \n",
       "4    172  ...       49      11   124      63        56      7   47        85   \n",
       "\n",
       "   ZALA  total  \n",
       "0    68   1807  \n",
       "1    26   1407  \n",
       "2    44   1284  \n",
       "3    31   1255  \n",
       "4    60   1478  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a column with the total of each case per day \n",
    "chickenpox['total'] = chickenpox.sum(axis = 1)\n",
    "chickenpox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rental-bachelor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rg = RandomForestRegressor()\n",
    "\n",
    "rg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reported-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared score: 95.10%\n",
      "mean absolute error: 7412.79\n",
      "mean squared error: 1415121.74\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "X = chickenpox.drop(['total', 'Date'], axis = 1)\n",
    "y = chickenpox.total\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "rg = RandomForestRegressor(n_estimators = 200)\n",
    "\n",
    "rg.fit(X_train, y_train)\n",
    "\n",
    "# making baseline predictions\n",
    "y_preds = rg.predict(X_test)\n",
    "\n",
    "baseline_metrics = evaluate_regression_preds(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-drain",
   "metadata": {},
   "source": [
    "## using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "detected-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   5.4s\n",
      "[CV] END max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   3.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   3.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   4.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   4.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   3.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   2.7s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   2.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   2.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   1.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   2.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1100; total time=   2.8s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1100; total time=   2.7s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1100; total time=   2.8s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1100; total time=   2.8s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1100; total time=   3.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# set up the grid\n",
    "grid = {'n_estimators': [100, 200, 500, 800, 1100],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 4, 6],\n",
    "        'min_samples_leaf': [1, 2, 3, 4]}\n",
    "\n",
    "# make results reproducible\n",
    "np.random.seed(10)\n",
    "\n",
    "# split into X nd y\n",
    "X = chickenpox.drop(['total', 'Date'], axis = 1)\n",
    "y = chickenpox.total\n",
    "\n",
    "# split into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15)\n",
    "\n",
    "# instantiate the model\n",
    "rg = RandomForestRegressor()\n",
    "\n",
    "# instantiating the random search\n",
    "rs_rg = RandomizedSearchCV(estimator = rg,\n",
    "                            param_distributions = grid,\n",
    "                            n_iter = 5, # n of different evaluations\n",
    "                            cv = 5, # cross-fold evaluation, total fits: n_iter * cv\n",
    "                            verbose = 2) # verbose indicate how much\n",
    "                                         # information to output while \n",
    "                                         # fitting\n",
    "# fitting the random search \n",
    "rs_rg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "satellite-treatment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "innovative-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.2s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.3s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.3s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   4.8s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   5.4s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   3.5s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   3.5s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   3.6s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   3.5s\n",
      "[CV] END max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   3.5s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   3.3s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   3.3s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   3.4s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   3.3s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   3.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   2.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   2.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   2.2s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   2.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=   2.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   2.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   2.1s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   2.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   1.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=   2.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   1.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   1.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   1.9s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   1.8s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=800; total time=   1.8s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_2 = {'n_estimators': [200, 800],\n",
    "          'min_samples_split': [2],\n",
    "          'min_samples_leaf': [1, 2, 3],\n",
    "          'max_features': ['auto', 'sqrt']}\n",
    "\n",
    "# GridSearchCV is very similar to RandomSearchCV\n",
    "gs_rg = GridSearchCV(estimator = rg,\n",
    "                     param_grid = grid_2,\n",
    "                     cv = 5,\n",
    "                     verbose = 2)\n",
    "\n",
    "gs_rg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "governmental-mongolia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-territory",
   "metadata": {},
   "source": [
    "## saving and loading our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-madrid",
   "metadata": {},
   "source": [
    "**using pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "professional-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "\n",
    "# saving our model\n",
    "# wb stand for \"write binary\"\n",
    "pk.dump(gs_rg, open('random_forest_regressor_model.pkl', 'wb'))\n",
    "\n",
    "# loading our model\n",
    "# rb stands for \"reading binary\"\n",
    "loaded_pk_model = pk.load(open('random_forest_regressor_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hindu-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared score: 96.03%\n",
      "mean absolute error: 6705.04\n",
      "mean squared error: 1146566.21\n"
     ]
    }
   ],
   "source": [
    "pk_y_preds = loaded_pk_model.predict(X_test)\n",
    "pickle_model_metrics = evaluate_regression_preds(y_test, pk_y_preds);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-spotlight",
   "metadata": {},
   "source": [
    "**using joblib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "periodic-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# saving our model\n",
    "dump(gs_rg, filename='random_forest_regressor_model.joblib');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "available-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_joblib_model = load(filename='random_forest_regressor_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "western-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared score: 96.03%\n",
      "mean absolute error: 6705.04\n",
      "mean squared error: 1146566.21\n"
     ]
    }
   ],
   "source": [
    "joblib_y_preds = loaded_joblib_model.predict(X_test)\n",
    "joblib_model_metrics = evaluate_regression_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sustained-friday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickle model</th>\n",
       "      <th>joblib model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R squared</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean absolute error</th>\n",
       "      <td>67.05</td>\n",
       "      <td>67.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean squared error</th>\n",
       "      <td>11465.66</td>\n",
       "      <td>11465.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pickle model  joblib model\n",
       "R squared                    0.96          0.96\n",
       "mean absolute error         67.05         67.05\n",
       "mean squared error       11465.66      11465.66"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = {'pickle model': pickle_model_metrics,\n",
    "                     'joblib model': joblib_model_metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-muscle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
